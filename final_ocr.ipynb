{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PaddleOCR\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/21 14:25:29] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\LENOVO/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\LENOVO/.paddleocr/whl\\\\rec\\\\ch\\\\ch_PP-OCRv3_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='c:\\\\Python310\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\LENOVO/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv3', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "ocr = PaddleOCR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/21 14:25:34] ppocr WARNING: Since the angle classifier is not initialized, the angle classifier will not be uesd during the forward process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/07/21 14:25:36] ppocr DEBUG: dt_boxes num : 13, elapse : 1.2385368347167969\n",
      "[2023/07/21 14:25:40] ppocr DEBUG: rec_res num  : 13, elapse : 3.83674955368042\n",
      "[[[[[560.0, 171.0], [998.0, 165.0], [999.0, 206.0], [560.0, 212.0]], ('Government of India', 0.854159414768219)], [[[542.0, 303.0], [832.0, 297.0], [832.0, 334.0], [543.0, 340.0]], ('Gagan Pramanik', 0.8915992975234985)], [[[545.0, 397.0], [1029.0, 390.0], [1029.0, 423.0], [546.0, 430.0]], ('Father:Mahananda Pramanik', 0.9299963116645813)], [[[545.0, 517.0], [897.0, 517.0], [897.0, 544.0], [545.0, 544.0]], ('G0/DOB:01/01/1978', 0.8553320169448853)], [[[548.0, 562.0], [704.0, 559.0], [704.0, 593.0], [548.0, 596.0]], ('/Male', 0.8947033882141113)], [[[564.0, 660.0], [932.0, 657.0], [932.0, 695.0], [564.0, 698.0]], ('233469361311', 0.927471935749054)]]]\n"
     ]
    }
   ],
   "source": [
    "img_path = 'doc.jpg'\n",
    "image = cv2.imread(img_path)\n",
    "result = ocr.ocr(img_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Government of India\n",
      "Gagan Pramanik\n",
      "Father:Mahananda Pramanik\n",
      "G0/DOB:01/01/1978\n",
      "/Male\n",
      "233469361311\n"
     ]
    }
   ],
   "source": [
    "for row in result[0]:\n",
    "    bbox = [[int(r[0]), int(r[1])] for r in row[0]]\n",
    "\n",
    "    # write text output on image at each line\n",
    "    cv2.putText(image, row[1][0], bbox[0],\n",
    "                cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.8, (255, 0, 0), 1)\n",
    "    cv2.polylines(image, [np.array(bbox)], True, (255, 0, 0), 1)\n",
    "\n",
    "cv2.imwrite(\"out_with_text.jpg\", image)\n",
    "concat_output = \"\\n\".join(row[1][0] for row in result[0])\n",
    "print(concat_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01/01/1978\n"
     ]
    }
   ],
   "source": [
    "match=re.findall(r'\\d+[/.-]\\d+[/.-]\\d{4}', concat_output)\n",
    "\n",
    "bill_date=\" \"\n",
    "bill_date=bill_date.join(match)\n",
    "print(bill_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233469361311\n"
     ]
    }
   ],
   "source": [
    "sent_tokens=nltk.sent_tokenize(concat_output)\n",
    "print(sent_tokens[0].splitlines()[5])\n",
    "number = sent_tokens[0].splitlines()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "price=re.findall(r'[\\$\\$\\£\\€\\₹](\\d+(?:\\.\\d{1,2})?)',concat_output)\n",
    "# print(price)\n",
    "if price:\n",
    "    price = list(map(float,price)) \n",
    "    # print(max(price))\n",
    "    total_bill=max(price)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SRI', 'KRISHNA', 'Veg', 'Restaurant', 'NewMuncipal', 'Bidg', 'Joban-Putra', 'Compound', 'NanaChowk', ',', 'Mumba1', '400007', 'Ph：23867544.23827326', 'TAXINVOICE', 'Date:01/07/17', '811No.：3//3', 'PBOY', ':', 'COUNTER', 'Particulars', 'Qty', 'Rate', 'Amount', 'MEDU', 'WADA', '165', '65', 'Sub', 'Total', ':', '65.00', 'D1s:810', '%', '6.00', 'Net', 'Total', ':', '59.00', 'CGST89', '%', '：', '5.31', 'SGST', '#', '9', '%', ':', '5.31', '1/1', 'Grand', 'Total', ':', '70', 'GSTNO27AADFH5037M1Z6', 'E.', '&', 'O.E', '.', '(', '06:56AM', ')', 'Thank', 'You', 'VisitAgain', 'Take', 'Away']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(concat_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SRI', 'KRISHNA', 'Veg', 'Restaurant', 'NewMuncipal', 'Bidg', 'Joban', 'Putra', 'Compound', 'NanaChowk', 'Mumba1', '400007', 'Ph', '23867544', '23827326', 'TAXINVOICE', 'Date', '01', '07', '17', '811No', '3', '3', 'PBOY', 'COUNTER', 'Particulars', 'Qty', 'Rate', 'Amount', 'MEDU', 'WADA', '165', '65', 'Sub', 'Total', '65', '00', 'D1s', '810', '6', '00', 'Net', 'Total', '59', '00', 'CGST89', '5', '31', 'SGST', '9', '5', '31', '1', '1', 'Grand', 'Total', '70', 'GSTNO27AADFH5037M1Z6', 'E', 'O', 'E', '06', '56AM', 'Thank', 'You', 'VisitAgain', 'Take', 'Away']\n"
     ]
    }
   ],
   "source": [
    "#we will remove punctuation\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "new_words = tokenizer.tokenize(concat_output)\n",
    "print(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sri', 'krishna', 'veg', 'restaurant', 'newmuncipal', 'bidg', 'joban', 'putra', 'compound', 'nanachowk', 'mumba1', '400007', 'ph', '23867544', '23827326', 'taxinvoice', 'date', '01', '07', '17', '811no', '3', '3', 'pboy', 'counter', 'particulars', 'qty', 'rate', 'amount', 'medu', 'wada', '165', '65', 'sub', 'total', '65', '00', 'd1s', '810', '6', '00', 'net', 'total', '59', '00', 'cgst89', '5', '31', 'sgst', '9', '5', '31', '1', '1', 'grand', 'total', '70', 'gstno27aadfh5037m1z6', 'e', 'o', 'e', '06', '56am', 'thank', 'you', 'visitagain', 'take', 'away']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english')) \n",
    "\n",
    "filtered_list=[w.lower() for w in new_words if w not in stop_words ]\n",
    "print(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entertainment\n",
    "entertainment = [] \n",
    "for syn in wordnet.synsets(\"entertainment\"): \n",
    "    for l in syn.lemmas(): \n",
    "        entertainment.append(l.name()) \n",
    "        \n",
    "l=['happy','restaurant','food','kitchen','hotel','room','park','movie','cinema','popcorn','combo meal']\n",
    "entertainment=entertainment+l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home utility\n",
    "home_utility=[] \n",
    "for syn in wordnet.synsets(\"home\"): \n",
    "    for l in syn.lemmas(): \n",
    "         home_utility.append(l.name()) \n",
    "l2=['internet','telephone','elecricity','meter','wifi','broadband','consumer','reading','gas','water','postpaid','prepaid']\n",
    "home_utility+=l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grocery\n",
    " \n",
    "grocery=[] \n",
    "for syn in wordnet.synsets(\"grocery\"): \n",
    "    for l in syn.lemmas(): \n",
    "         grocery.append(l.name())\n",
    "l3=['bigbasket','milk','atta','sugar','suflower','oil','bread','vegetabe','fruit','salt','paneer']\n",
    "grocery+=l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investment\n",
    "investment=[] \n",
    "for syn in wordnet.synsets(\"investment\"): \n",
    "    for l in syn.lemmas(): \n",
    "         investment.append(l.name()) \n",
    "l1=['endowment','grant','loan','applicant','income','expenditure','profit','interest','expense','finance','property','money','fixed','deposit','kissan','vikas']\n",
    "investment=investment+l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#travel and transportation\n",
    "transport=[]\n",
    "for syn in wordnet.synsets(\"car\"): \n",
    "    for l in syn.lemmas(): \n",
    "         transport.append(l.name()) \n",
    "l4=['cab','ola','uber','autorickshaw','railway','air','emirates','aerofloat','taxi','booking','road','highway']\n",
    "transport+=l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shopping\n",
    "shopping=[]\n",
    "for syn in wordnet.synsets(\"dress\"): \n",
    "    for l in syn.lemmas(): \n",
    "         shopping.append(l.name()) \n",
    "l4=['iphone','laptop','saree','max','pantaloons','westside','vedic','makeup','lipstick','cosmetics','mac','facewash','heels','crocs','footwear','purse']\n",
    "shopping+=l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, inv, g, s, t, h = False, False, False, False, False, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in filtered_list:\n",
    "    if word in entertainment:\n",
    "        e = True\n",
    "        break\n",
    "    elif word in investment:\n",
    "        inv = True\n",
    "        break\n",
    "    elif word in grocery:\n",
    "        g = True\n",
    "        break\n",
    "    elif word in shopping:\n",
    "        s = True\n",
    "        break\n",
    "    elif word in transport:\n",
    "        t = True\n",
    "        break\n",
    "    elif word in home_utility:\n",
    "        h = True\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entertainment\n"
     ]
    }
   ],
   "source": [
    "category=''\n",
    "if(e):\n",
    "    print(\"entertainment\")\n",
    "    filename='{}.csv'.format('entertainment')\n",
    "    category='entertainment'\n",
    "elif(inv):\n",
    "    print(\"investment\")\n",
    "    filename='{}.csv'.format('investment')\n",
    "    category='investment'\n",
    "elif(s):\n",
    "    print(\"shopping\")\n",
    "    filename='{}.csv'.format('shopping')\n",
    "    category='shopping'\n",
    "elif(g):\n",
    "    print(\"grocery\")\n",
    "    filename='{}.csv'.format('grocery')\n",
    "    category='grocery'\n",
    "elif(t):\n",
    "    print(\"transport\")\n",
    "    filename='{}.csv'.format('transport')\n",
    "    category='transport'\n",
    "elif(h):\n",
    "    print(\"home utility\")\n",
    "    filename='{}.csv'.format('home')\n",
    "    category='home'\n",
    "else:\n",
    "    print(\"others\")\n",
    "    filename='{}.csv'.format('others')\n",
    "    category='others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
